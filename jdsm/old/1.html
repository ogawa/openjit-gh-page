<html>
<head>
<meta http-equiv="Content-Type" content="text/html;charset=x-sjis">
<!--link rel="stylesheet" type="text/css" href="./style.css"-->
<title>News</title>
</head>
<body>
[ 前章
| <a href="index.html">目次</a>
| <a href="2.html">次章</a> ]
<hr>
<h1>1 序論</h1>

<a name="1">
<h2>1.1 背景</h2>
<p>
近年の計算機構成技術の発展によって、ソフトウェアの実行環境はますます多様
化している。この計算機構成技術の発展はハードウェアの急速なコモディティ化
と対応するものである。特に、並列計算機環境においては、このハードウェアの
コモディティ化によってPCクラスタ・WSクラスタという形態の分散メモリ型並列
計算機が多数開発されている。
</p>

<p>
しかし、このような計算機環境の多様化に肝心のソフトウェアが追従できている
とは言いがたい。現在、多様な計算機環境に適合しうる、保守性や可搬性を重視
した汎用的なソフトウェアや、さらに、それを実現するためのフレーム
ワークすら十分でないのが現状である。例えばオブジェクト指向技術は確かにソフト
ウェアの効率の良い構築フレームワークを与えるが、実行環境の変化に適合し
た最適化を行うには十分ではない。
</p>

<p>
特に並列計算機環境においては、メモリモデルやプロセッサ構成・ネットワーク
の構成や形態、さらにプログラミングモデルの違いなど、その構成の多様性から
従来の手法での解決が難しい。従来の手法とは、
<ul>
<li> HPFに代表される並列プログラミング言語
<li> SUIFなどの自動並列化コンパイラ
<li> PVMやMPIなどのメッセージ通信ライブラリ
</ul>
のいずれかを用いることで実現されていた。しかし、並列プログラミング言語や
自動並列化コンパイラは、言語拡張が必要であったり十分な性能を達成できな
いなどの問題がある。メッセージ通信ライブラリではプログラムの記述性や保守
性が損なわれ、実行環境を強く意識したプログラミングを行わなければ、高い性
能を発揮することが難しいなどの問題がある。さらに、処理系自体の可搬で高効
率な実装や柔軟な言語拡張が難しいという問題もある。
</p>

<p>
以上のような観点から、計算機環境、特に並列計算機環境で利用されるソフトウェ
アには<b> プラットフォームポータビリティ</b> が強く求められる。具体的には、
<ul>
<li> ソフトウェア(システム・処理系)の可搬性
<li> 実行環境への最適化
<li> 性能の可搬性
</ul>
が求められる。
</p>

<a name="2">
<h2>1.2 本研究の目的と成果</h2>
<p>
前節で述べた並列計算機環境におけるプラットフォームポータビリティを実現す
る手法を提案し、プラットフォームポータビリティを確保できることを示す。
</p>
<p>
本研究で提案する手法は、自己反映計算(リフレクション)を用いてソフトウェア
のプラットフォームポータビリティを実現する方法である。自己反映計算は前節
で述べたような問題を整合的かつ柔軟に解決する方法であると考える。自己反映
計算では通常の計算を表す従来からのベースレベルのコードに加え、自己の計算
系を表すメタレベルのコードを記述することができるため、従来例外的かつ固定
的に扱わざるを得なかった例外処理や資源管理を整合的に処理できる。特に、
Open Compilerと呼ばれる、コンパイラのコンパイル時の挙動を自己反映的に変
更する機能を持つシステムでは、これらの機能を容易に実現できることが知られ
ている。Open Compilerではコンパイラをオブジェクト指向設計に基づきモジュー
ル化してユーザから変更可能にし、更にコンパイル時に静的にメタ計算を行うこ
と(Compile-time MOP)によって言語の拡張やアプリケーション固有の最適化など
を行うことができる。
</p>
<p>
本研究では、クラスタ型並列計算機上にマルチスレッドプログラムが動作可能な
環境を提供する。この理由には、
<ul>
<li> ハードウェアのコモディティ化によってコストパフォーマンスの高いク
 ラスタ型並列計算機が急速に普及しており、性能やシステムの拡張性に優れて
       いること
<li> マルチスレッドプログラミングが一般に並列プログラミングにおいて容
 易なモデルとされていること
</ul>
が挙げられる。つまり、クラスタ型並列計算機上にマルチスレッドプログラムが
動作可能な環境は並列計算において理想的な環境であると言える。
</p>

<p>
しかし、クラスタ型並列計算機では、MPIなどのメッセージパッシングライブラ
リなどを用いた、分散メモリモデルのプログラミングであり、マルチスレッドプ
ログラムは基本的に共有メモリマシンでしか動作しないため、対象となる計算機
は共有メモリ計算機である必要がある。
</p>

<p>
そこで、マルチスレッドプログラムを分散メモリ環境で実現するには、各ノード
のメモリを透過的に扱える必要がある。そこで、ポータブルなソフトウェア分散
共有メモリを実現し、その上でマルチスレッドプログラムを動作させることが考
えられる。しかし、ここでもポータビリティ上の問題が発生する。マルチスレッ
ドプログラムを、ソフトウェア分散共有メモリシステム上で動作させるためには、
少なからずもとのマルチスレッドプログラムを修正する必要が出てくるためであ
る。
</p>

<p>
そこで、本研究では、この直交する2つの要素である、クラスタ型並列計算機と
マルチスレッドプログラミングを、自己反映計算とソフトウェア分散共有メモリ
を用いて実現する。つまり、自己反映計算とソフトウェア分散共有メモリを用い
て、並列実行環境上でプラットフォームポータビリティを実現する並列プログラ
ミング環境の実現する。
</p>

<p>
本研究では、Java言語に対して実現することとした。
Java言語を利用する利点としては、
<ol>

<li> 言語仕様において、ソースコードレベルだけでなく、コンパ
イルされたバイトコードレベルにおいてもポータビリティを提供している

<li> C++言語と同様にオブジェクト指向言語であるため、プログラムの保守な
       どが容易である

<li> 言語仕様においてスレッド・ネットワークのサポートがあるため、ネッ
 トワーク環境や並列プログラミングへの親和性が高い

<li> ネットワーク経由でプログラムをダウンロードすることが可能

<li> C++言語に比べ、自己反映計算を適用可能なレベルが多い

</ol>

が挙げられる。1についてみると、自己反映計算によるプログラムの変換は純粋
に機能拡張や環境特化にしぼられるため、不要な変換(スレッドモデルの違いな
ど)を考慮する必要がない。4では、必要に応じてプログラムをダウンロードでき
るため、環境に特化したプログラムをネットワークからダウンロードしてくる、
環境に特化したメタクラスをダウンロードしてくると言ったことが可能となる。
さらに、自己反映計算を適用可能なレベルが、ソースコードレベル、バイトコー
ドレベル、プログラムロード時、JITコンパイル時など多くの場合が考えられる
(図1)。それぞれのレベルにおいて様々な機能拡張
や最適化を行うことができる。しかし、既存の環境を変更するような手法、特
にランタイム(JVM)の変更を行うような手法は、ポータビリティの点から利用す
べきではない。例えば、図1の実行時に自己反映
計算を行うシステムであるMetaXaなどはJVMへの変更が必要となる。JITコンパイ
ル時に自己反映計算を行うOpenJITは、アーキテクチャ依存部分(マシンコード生
成部)が独立しているため、カスタムJITコンパイラではあるが、可搬性は高く、
幅広い処理が可能である。
</p>

<table align=center border=2>
<tr>
<th><nobr>タイミング</nobr></th>
<th>処理系</th>
<th>処理内容</th>
<th>長所</th>
<th>制限</th>
</tr>
<tr>
<th>ソースコード</th>
<td>EPP</td>
<td>プリプロセッサ</td>
<td>言語使用の拡張が容易</td>
<td>ソースコードが必要</td>
</tr>
<tr>
<th>コンパイル時</th>
<td>OpenJava</td>
<td>Compile-Time MOP</td>
<td>言語使用の拡張が容易</td>
<td>ソースコードが必要</td>
</tr>
<tr>
<th>バイトコード</th>
<td>BCA</td>
<td>バイナリ変換器</td>
<td>ソースコードが不要</td>
<td>JVMのクラスファイルロード機構に変更が必要</td>
</tr>
<tr>
<th>実行時</th>
<td>Kava、MetaXa</td>
<td>Reflective JVM</td>
<td>動的な拡張が可能</td>
<td>カスタムJVMが必要</td>
</tr>
<tr>
<th>JITコンパイル時</th>
<td>OpenJIT</td>
<td>Compile-Time MOP</td>
<td>ソースコードが不要、
ソースレベルからバイナリレベルまでの最適化や機能拡張が動的に可能</td>
<td>カスタムJITコンパイラが必要</td>
</tr>
<caption>図1. Javaにおける自己反映計算の実現可能なレベル</caption>
</table>

<p>
しかし、Java言語を利用した場合、考慮すべき点がある。

<ol>
<li> 実行時性能
<li> JVM(Java Virtual Machine)への依存
</ol>

1に関しては、必ずしも大きな問題ではない。なぜなら、JITコンパイラや
GC(Garbage Collection)、Java言語向けの最適化手法などが数多く研究され、C
言語並の性能を達成することが可能である。2は、本研究の手法を用いることで
解決される。Java言語のポータビリティはJVMのポータビリティに依存しており、
JVMの提供する機能に制限されていた。しかし、本研究の提案する手法 --- 自己
反映計算の適用 --- によってJVMに縛られない機能拡張や実行環境特化が行える。
</p>

<hr>
[ 前章
| <a href="index.html">目次</a>
| <a href="2.html">次章</a> ]
</body>
</html>
