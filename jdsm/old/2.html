<html>
<head>
<meta http-equiv="Content-Type" content="text/html;charset=x-sjis">
<!--link rel="stylesheet" type="text/css" href="./style.css"-->
<title>News</title>
</head>
<body>
[ <a href="1.html">前章</a>
| <a href="index.html">目次</a>
| <a href="3.html">次章</a> ]
<hr>
<h1>2 関連研究</h1>

<p>
本章では、本研究で構築するシステムを構成する要素技術とそれらに対して行わ
れている研究について述べる。
</p>

<p>
はじめに分散共有メモリ、特にソフトウェアでの実現に重点をおいて説明する。
関連研究においては、ソフトウェア分散共有メモリの研究のうち、Shasta、
TreadMarks、Java言語上に実現されたソフトウェア分散共有メモリシステムであ
るcJVM、Java/DSMについて述べる。
また、本研究で対象としているクラスタ型並列計算機向けシステムやそれらで利
用されている高速な通信ライブラリなどについても述べる。
</p>

<p>
自己反映計算においては、自己反映計算の理論について述べるとともに、
関連研究としてC++言語、Java言語向けに実現しているシステム(OpenC++、
OpenJIT、EPPなど)について述べる。
</p>

<a name="1">
<h2>2.1 分散共有メモリ</h2>
<p>
分散共有メモリとは、異なるノード上に存在するメモリを透過的に扱う手法であ
る。
</p>
<p>
他のノードが持つメモリへのアクセスは最終的には I/Oなどの手続きで解決さ
れるが、その手続きの指定は明示的ではない。つまり、
<ul>
<li> プログラム作成時に、プログラム作成者に、注釈(annotation)を付けさせる。
<li> コンパイル時に、コンパイラに、静的に検出させる。
<li> 実行時に、OSないしランタイムライブラリに、動的に検出、処理させ
       る。
</ul>
といった方法でプログラム作成者から見た手続きの指定を隠蔽して、メモリ
アクセスに類似したインタフェースだけを提供するものである。
</p>

<h3>2.1.1 アルゴリズム</h3>
<p>
分散共有メモリの実現で最も重要なのは、分散したメモリの一貫性を保つことで
ある。このメモリの一貫性処理は
分散共有メモリ、特にソフトウェア分散共有メモリにおいて、アプリケーション
の性能の大幅な低下を招く危険性が高く、効率の良い実装が求められる。
効率の良い実装としてポイントとなる点は

<ul>
<li> メモリ一貫性処理のオーバーヘッド
<li> False Sharing
</ul>

である。メモリ一貫性処理のオーバーヘッドとしては、メモリアクセス(領域や
状態)のチェックやメモリの転送に伴う通信オーバーヘッドなどが挙げられる。
これを低減するには高速なネットワークを利用する、メモリ管理の粒度を大きく
してメモリアクセスチェックを減らすなどの方法が挙げられる。
False Sharingでは、異なるノードが同じメモリ領域を頻繁にアクセスしあうこと
によって引き起こされる、メモリ一貫性処理のオーバーヘッドがある。False
Sharingを減らすには、メモリ管理の粒度を小さくする、メモリへの複数ノード
からの書き込み許すなどの方法がある。
</p>
<p>
分散共有メモリで利用されるメモリの一貫性を保つモデルとしては以下のような
ものが存在する。
<dl>
<dt>Strict Consistency
<dd>
<p>
どのような共有変数に対するロードも、一番最近にストアされた値を読み込んで
くるようなモデル。つまり、唯一の絶対時間が存在し、システム中の全てのモジュー
ルはその絶対時間の下で動かなければならない。この実装は非常に困難である。 
</p>

<dt>Sequencial Consistency
<dd>
<p>
共有メモリ型並列計算機で、あるプログラムを実行した時、その実行時間が、そ
のプログラムを実行する全てのプロセッサの命令列をある規則にしたがって逐次 
に実行した時の実行した時の実行結果と同じであり、個々のプロセッサ上での命
令の順番はプログラムに書かれた順番と一致するモデル。
</p>

<dt>Weak Consistency
<dd>
<p>
全ての同期命令は他の全てのプロセッサに関するロードおよびストアが完了した
後に実行され、全てのロードおよびストアは他の全てのプロセッサに関する同期
命令が完了した後に実行されるモデル。
</p>

<dt>Release Consistency
<dd>
<p>
他の全てのプロセッサに関して通常のロードやストアが実行される前に、それ以
前の全ての獲得命令が完了している必要があり、他の全てのプロセッサに関して
解放命令が実行される前に、それ以前の全てのロードやストア命令が完了してい
なければならないモデル。
</p>

<dt>Lazy Release Consistency
<dd>
<p>
Release Consistencyを緩めたモデル。ある区間ごとに共有メモリへのアクセス
情報を保持し、区間を出るときに全ノードで同期をとり、そのメモリ差分(diff)
をとってメモリの内容を更新する。つまり、ある区間ではメモリの一貫性は崩れ
るが、その区間を出るときには一貫性が保たれる。
</p>
</dl>

従来、Release Consistencyモデルもしくはそれを改良したモデルが多く用いら
れてきたが、最近では、性能からLazy Release Consistencyモデルが利用される
ことが多い。
さらに、メモリ情報の保持の方法などからも分類でき、以下のような手法がある。

<dl>
<dt>migration
<dd>
<p>
共有メモリを各ホストに分散させ、なんらかのメモリアクセスがあった時、その
領域がローカルになければその領域を持つホストを見つけ出して、その領域をロー
カルに移動するアルゴリズムである。メモリへのアクセスはそのホスト上で動い
ているプロセスしかできないので、Single reader/Single writer と呼ばれる。
</p>
<p>
このアルゴリズムの利点はプロセスがローカルにある共有メモリへアクセスする
時に通信のコストがかからないことである。もう一つの利点は、もし共有メモリ
ブロックのサイズが仮想メモリのページサイズと同じであれば、ホストのオペレー
ティングシステムの仮想メモリシステムに統合できることである。これは、もし
共有メモリがローカルにある場合、それはプログラムの仮想アドレス空間にマッ
ピングすることができ、メモリアクセスが通常の命令で可能になる。ローカルに
ないメモリへのアクセスがあった場合、ページフォルトが発生するが、このペー
ジフォルトをトラップすることにより、そのメモリ領域をリモートから獲得して
ローカルにマッピングすることができる。
</p>
<p>
このアルゴリズムの欠点は共有メモリ領域がホスト間を振り回される恐れが大い
にありうることである。これはプログラム作成時に共有メモリのブロックサイズ
を調節することにより、ある程度制御できる。また、ある共有メモリブロックを
持つリモートホストを見つけるために、マルチキャストをする必要がある。これ
はネットワークの負荷を増大させる。しかし、その共有メモリブロックの所有者
を常に把握する管理サーバーを設けることにより、負荷を分散させることができ
る。
</p>

<dt>Write Invalidate
<dd>
<p>
このアルゴリズムは共有メモリの複数のコピーを許すが、その領域へ書き込みが
あった場合、他のマシンが持つコピーを無効化しなければならない Multi
reader/Single writerタイプである。
</p>
<p>
あるマシンでローカルにない共有メモリへのreadアクセスがあった場合、そのマ
シンはその共有メモリの所有者へその共有メモリのコピーを要求する。リクエス
トを受けたマシンではリクエストしたマシンへコピーを送り、その領域のコピー
をもつマシンのリストへリクエストしたマシンのエントリーを加える。
</p>
<p>
あるマシンでローカルにある共有メモリへのwriteアクセスがあった(その共有メ
モリの所有者である)場合、その共有メモリのコピーをもつマシンへその領域の
無効を伝える。無効の通知を受けたマシンではその領域を破棄する。そのマシン
は再びその領域へのアクセスがない限り、コピーを持たない。そして、その領域
へ書き込むことができる。
また、あるマシンでローカルにない共有メモリへのwriteアクセスがあった(その
共有メモリの所有者でない)場合、その共有メモリの所有者へその領域のコピー
と所有権を要求する。要求を受けたマシンはその領域のコピーを返し、所有権を
渡す。所有権を獲得したマシンではその共有メモリの無効をその共有メモリのコ
ピーを持つマシンへ伝える。そして、その領域へ書き込むことができる。
</p>

<dt>Write Update
<dd>
<p>
このアルゴリズムは共有メモリへ書き込むまさにその時もその領域のコピーを持
つことを許している Multi reader/Multi writerタイプである。
</p>
<p>
ある共有メモリへのreadアクセスがあった場合、それがローカルになければその
領域をもつホストにその領域のコピーを要求する。ある共有メモリへのwriteア
クセスがあった場合、シーケンサに書き込むデータを送信する。シーケンサは書
き込みのデータを受信すると、そのデータにシーケンス番号を割り当てて、すべ
てのホストに変更をマルチキャストする。変更を受け取ったホストでは、シーケ
ンス番号順にメモリの内容を更新する。もしこのシーケンス番号に矛盾が生じた
場合はシーケンサに再送信が要求される。このためシーケンサでは最近の書き込
み要求の情報を保持しておく必要がある。書き込み要求を出したホストはこのマ
ルチキャストを受けると、書き込み要求が受理されたと見なして、ローカルのメ
モリを更新する。
</p>
<p>
このアルゴリズムでは、一回の書き込みごとにホストの数＋２回の送信が発生す
るため、ネットワークの負荷が大きい。また、一度ある共有メモリのコピーを所
有したホストはずっとそのコピーを保持しなくてはならない。
</p>
</dl>
実装の容易さ、性能面などからWrite Invalidateが用いられることが多いが、最
近では、ネットワークの高速化などにより、Write Updateプロトコルやそれを改
良したAutomatic Update Protocolなどが提案されている。

</p>
<h3>2.1.2 関連研究</h3>

<h4>ソフトウェア分散共有メモリ</h4>

<h5>Shasta</h5>
<p>
Shasta[22]は分散メモリをもつクラスタ型計算機シ
ステム上で共有アドレス空間をサポートするシステムである。実装環境には
DECのAlphaワークステーションが用いられている。
</p>
<p>
Shastaは他のソフトウェア分散共有メモリシステムに比べて以下のような特徴を
持っている。
<ul>
<li> 疎粒度で共有データの一貫性を保つことができる
<li> 一貫した粒度で単一のアプリケーションにおいて異なる共有データの構造を許す
<li> 共有メモリ向けプログラムをバイナリレベルでプログラム変換を行い、
       分散共有メモリ環境上で動作可能としている
</ul>
プログラム変換ではメモリのロードとストアをフックするようにプログラムを書
き換えることによって共有アドレス空間を実装している。各共有メモリへのロー
ドとストアでは、そのデータがローカルであるかどうかのチェックを行うコード
を挿入し、必要があれば通信を行う。これらのチェックによる実行時のオーバヘッ
ドを減らすためにShastaでは多くの工夫を行っている。
</p>
<p>
Shastaはソフトウェアで実装されているため、異なるタイプのキャッシュコーヒ
レンスプロトコルのサポートにおいて多くの柔軟性を提供している。Shastaでは
relaxedメモリーモデルや複数の通信粒度のサポートなどを含めた多くの最適化
を組み合わせたキャッシュコーヒレンスプロトコルを実装している。
</p>
<p>
Shastaで効率のよい実装の実現のために行われているテクニックは、共有アドレ
ス空間のレイアウト(メモリの管理テーブルと実際のアドレスとの変換をシフト
演算のみで行えるようにアドレスの割当を変更)、効果的な実行を行うためのチェッ
クコードのスケジューリング(チェックのバッチ処理化など)、チェックのために
値のロードしか行わないシンプルな命令の使用、チェックコードによって起こる
キャッシュミスの削減、複数のロードおよびストアのためのチェックの組み合わ
せなどがある。
</p>
<p>
しかし、プログラム変換がバイナリレベルであるため、オーバーヘッドの少ない
変換を施せる反面、ポータビリティが大幅に損なわれている。特にShastaでは
Alphaのメモリチャネルに特化しているため、異なるシステムへの移植は困難で
ある。
</p>

<h5>Java/DSM</h5>
<p>
Java/DSM[28]はTreadMark[1]チームによる、異機
種分散環境のサポートを目指し、下位のDSMシステムとしてTreadMarksを用いた
カスタムJVMである。
</p>
<p>
Java/DSMではすべてのノードにJVMが存在し、すべてのオブジェクトが共有メモ
リ領域へ割り当てられる。リモートのオブジェクトはローカルオブジェクトと同
じように扱うこと(メソッド呼び出しやインスタンスへのアクセスなど)ができる。
各ノード間のスレッドの割り当ては自動的に行われ、スレッドの移動などはでき
ない。
</p>
<p>
ガーベッジコレクションは各ノードで独立して行われるのが望ましいため、各ノー
ドでリモートノードからの参照を管理する必要がある。そこでガーベッジコレク
タはリモートノードからのローカルオブジェクトへの参照を保持するexportリス
トとリモートオブジェクトへの参照を保持するimportリストの2つのリストを管
理する。そしてメッセージをリモートノードへ送る前に、DSMランタイムがガー
ベッジコレクタを呼び出し、送られるべきメッセージのチェックをさせる。ガー
ベッジコレクタはローカルオブジェクトへの有効な参照であるかをチェックして
exportリストへ追加する。メッセージが受け取るときもまた、DSMランタイムが
ガーベッジコレクタを呼び出す。ガーベッジコレクタでは有効なリモート参照で
あるかをチェックしてimportリストへ追加する。Ownerではweighted reference
countingを用いて、exportリストからリモートからの参照を削除するかどうかを
決めている。
</p>
<p>
TreadMarksはページベースのDSMシステムであり、異機種分散環境で必要となる
データの変換(big endian$<$-$>$little endianなど)は行わないので、JVMの方
で行う必要がある。そのため、データ変換ではそのデータの型情報が必要となる。
通常のJVMではオブジェクトは、実際のデータへの参照であるbodyと、bodyへのポイン
タと型情報を格納した構造体へのポインタの2つのフィールドを持つhandleを持っ
ている。これによって各オブジェクトがどのようなデータ型であるかが判明する。
Java/DSMで用いるJVMでは効率のために、bodyにhandleへのバックポインタを持
たせている。これによってどんなアドレスからもオブジェクトのサイズや型情報
を得ることができ、データ変換が可能となる。
</p>
<p>
この他のJava/DSMでのJVMの変更点はヒープをTreadMarksの共有メモリ割り当て
ルーチンを用いて割り当てていること、JVMによってロードされるクラスは共有
メモリ領域に置かれることである。
</p>
<p>
Java/DSMにおいても、システムのポータビリティは非常に低い。なぜなら、
<ul>
<li> 分散共有メモリ機構を提供するためにTreadMarksを利用している
<li> JVMへ(大幅な)変更を施している
</ul>
ためである。特にJVMへの変更により、システムのポータビリティを低下させる
だけではなく、既存のJITコンパイラなどが利用不可能となるため性能面でも不
利になると考えられる。もちろん、カスタムJVMへのカスタムJITコンパイラを実
現することも考えられるが、Java/DSMの場合、分散環境・下位の分散共有メモリ
システムを考慮する必要もあり、JITコンパイラの実装は容易ではなく、その移
植も膨大な労力が必要となるであろう。
</p>
<p>
また、TreadMarksはページベースの分散共有メモリシステムであるため、Javaの
Objectなどのようなページサイズに比べはるかに小さいデータを扱う場合、
False Sharingが再び問題となる可能性もあり、十分な性能が期待できない。
</p>

<h5>cJVM</h5>
<p>
cJVM[2]はサーバーアプリケーション向けのクラスタ(分散メ
モリ環境)用のJVMで、クラスタ上にSingle System Imageを実現している。cJVM
の特徴は分散ヒープモデル、透過的なメソッドシッピングをサポートしたスレッ
ドモデル、分散クラスローディングである。現在、プロトタイプがMyrinet
で接続されたPC(IBM Intellistation)のWindowsNT上で動作しており、通信レイ
ヤではHPVM上のMPIを用いている。
</p>
<p>
以下ではcJVMの特徴とその実現方法について述べる。

<dl>
<dt>分散ヒープとオブジェクトモデル
<dd>
<p>
分散されたオブジェクトへのアクセスのためにmaster-proxyモデルを用いている。
あるオブジェクトが作られたノードにそのオブジェクトのmasterコピーがあり、
それ以外のノードではそのオブジェクトへのproxyが使われる。アプリケーショ
ンでこのmasterとproxyを区別するために、「ある1つのメソッドに対して複数の
実装を許す」という新たなオブジェクトのモデルを定めている。そしてこのモデ
ルでは、そのオブジェクトごとに適切な実装のメソッドを切り替えて呼び出すこ
とができる。
</p>
<p>
cJVMでは、あるノードがproxyへアクセスするときの方法は、メソッドシッピン
グである。proxyはあるメソッドの実行をmaster copyへリダイレクトする。これ
はメソッドテーブルを拡張することによって実現されている。master オブジェ
クトでは通常のメソッドテーブルを保持している。proxyオブジェクトのメソッ
ドテーブルは、masterオブジェクトと同じメソッドが用意されているが、それぞ
れのメソッドはmasterオブジェクトへリクエストを送り結果を受け取るものであ
る。このproxyオブジェクトでのコードはクラスがロードされたときに生成され
る。さらに、バイトコードがヒープへアクセスするのでバイトコードも修正する
必要がある。バイトコードがアクセスしようとするヒープがローカルにあるかを
チェックして、なければリモートアクセスを行う。このリモートアクセスに対処
するために各ノードではリクエストを処理するサーバースレッドが動いており、
リクエストを受け付けて結果を返す処理を行っている。
</p>

<dt>スレッドモデル
<dd>
<p>
スケーラビリティの点から、異なるアプリケーションスレッドは異なるノードで
実行される必要がある。そこでスレッドの生成方法を変更し、スレッドはロード
バランス関数で決められる最適なノードで生成されるようにする(ロードバラン
ス関数は変更可能)。さらにメソッドシッピング(のリクエスト)がきた場合、ア
プリケーションスレッドの論理的な一意性を保つために、新たにOSレベルのスレッ
ドを生成して実行する。
</p>
<dt>プログラム解析
<dd>
<p>
cJVMではクラスのロード時に手続き間のフロー解析を行う。このフロー解析では
インスタンスメソッドのためのthis参照の仕様を追跡し、新しく生成されるオブ
ジェクトの型を解析し、メソッドが使うバイトコードを決定する。これによって
メソッドのヒープへのアクセス方法と、proxyの実装方法によって、メソッドを
クラスわけできる。また、常にローカルでアクセスされるヒープを決めることが
できる。さらにメソッドの実装を直接クラスタを利用するように変更することも
できる。
</p>
<dt>分散クラスロード
<dd>
<p>
cJVMでは各ノードで、独立して利用するクラスのコードのコピーを持っている。
まず、コンスタントプールなどのクラスの内部のデータ構造を正しく構築する直
接的な方法として各ノードでコードをロードする。また、アプリケーションから
はクラスはオブジェクトとして見えるので、もしクラスが複数のノードで独立し
てロードされても、1つのオブジェクトに見える必要がある。さらに、クラスが
初期化されるときアプリケーションやクラスの初期化メソッドが実行されるが、
2回以上実行されてはならない。そこで、オブジェクトのmaster-proxyモデルと
同じようにクラスにもmasterコピーを用意する。そしてそのクラスをロードする
ノードでは、部分的にロードしてmasterノードへ問い合わせる。
</p>
</dl>

以上のように、cJVMではJava RMI的な実現方法をとっており、それをJVM内部で
処理するようにしている。このような方法はJavaとの親和性が高いが、
master-proxyモデルによるオーバーヘッドが問題となる。しかし、cJVMシステム
は科学技術計算や数値計算ではなく、一般的なネットワークにおける共同作業用
アプリケーション的なものをターゲットとしているため、必ずしも高速性が求め
られるわけではないようである。
</p>
<p>
cJVMにおいてもJava/DSMシステムと同じように、JVMへの変更によりポータビリ
ティと性能が損なわれる。しかし、cJVMではJITコンパイラを利用できるようイ
ンターフェースは定めてあるようである。また、メモリの管理単位がJavaの
Object単位であるため、一般にFalse Sharingは起きにくいが、Objectが巨大に
なる(フィールドが多いなど)ような場合は考慮されていないため、性能低下を招
く危険性がある。なお、Primitive型はObjectとは異なり、メッセージパッシン
グでデータのやりとりが行われている。
</p>

<h5>TreadMarks</h5>

<p>
TreadMarks[1]はワークステーションクラスタにお
いて並行コンピューティングをサポートするシステムである。TreadMarksはメモ
リコンシステンシーモデルに リリースコンシステンシーモデルをさらに緩めた
Lazy リリースコンシステンシーモデルを採用している。これにより通信による
オーバーヘッドを削減している。また、複数の書き込みを許すことにより、
false sharingをの影響を減らすことによっても通信によるオーバーヘッドを削
減している。ただ、通信のオーバーヘッドに比べてメモリ管理のコストは小さい
という考えから、メモリ管理における最適化や改良などは行われていない。
</p>

<h4>クラスタ向けソフトウェアなど</h4>
<p>
以下では、クラスタ型並列計算機向けの並列実行環境やそれらで利用されている
通信インタフェースなどについて述べる。
</p>

<h5>VIA</h5>

<p>
VIA(Virtual Interface Architecture)[9]とは、(LANやWANよ
りも密集した) System Area Network (SAN)向けの通信フレームワークである。
</p>
<p>
VIAはハードウェア保護のチェックとネットワークへの直接アクセス用の構造を
確立するユーザーレベルのネットワークを提供する。従来のネットワークインター
フェースでの経験を考慮して、廉価な実装も可能としている。また従来のイーサー
ネットカードと同様のdescriptor processingモデルだけでなく通信ライブラリ
インタフェースも提供する。
</p>
<p>
ユーザーレベル通信では、共有通信資源への保護されたアクセスを提供する必要
がある。従来、ユーザープロセスは通信をするためにシステムコールを発行する。
ネットワークのスタックは、物理的なネットワークカードを操作するカーネルの
デバイスドライバを通して、多くのプロセスからのネットワークへの通信を多重
化している。このような方法ではユーザーのアドレス空間をNIC上へマップした
り、カーネルを経由しないことが容易なため、一人のユーザーへの通信を制限し
たり、ある通信が他のプロセスの通信を妨げることが可能となってしまう。ユー
ザーレベルネットワークでは、ユーザープロセスがネットワークのエンドポイン
トをあらわすユーザーのアドレス空間へアクセスすることを許している。このエ
ンドポイントへ書いたり読み込んだりすることによってメッセージを送信したり
受信したりする。
</p>
<p>
VIAではエンドポイントはネットワークインタフェースのディスクリプタキュー
に似ており、virtual interface(VI)と呼ばれる。OSはユーザープロセスのアド
レス空間へNICの資源にマップすることでVIの生成と破棄を行う。これによって
アプリケーションは他のプロセスのVIへアクセスすることはできなくなる。
VIAは、point-to-pointでconnection-orientedであり、OSがVIの接続や切断に関
与したり接続の量や詳細をコントロールすることでネットワークの利用をOSが制
御することを提供している。
</p>
<p>
VIのセットアップ・接続・管理はユーザーレベルのライブラリを通してカーネル
ドライバと対話的に行われる。カーネルドライバは、ユーザーレベルのプロセス
が行わない、VIの生成接続などをNICへ通知するためのNIC資源へアクセスする。
</p>
<p>
各VIは送信と受信のキューのペアとそのペアへのドアベルを持っている。これら
へは直接アクセスできず、ユーザーレベルのライブラリを経由してアクセスされ
る。データバッファとキューはネットワークカードがアクセスするホストのメモ
リ領域に割り当てられる。VIAではこれらのメモリ領域をregistered memoryと呼
ぶ。アプリケーションによるパケットの送受信は、適切なディスクプリタを生成
し、ユーザーレベルライブラリによるNICの適当なドアベルを鳴らすことによっ
て行われる。このときアドレスマッピングはOSによって行われるため、正確な保
護と仮想化が維持される。
</p>
<p>
このユーザーレベルライブラリ上にMPIなどを実装することは可能だが、VIのバッ
ファにマップできないデータ領域がある場合はデータのコピーが必要となる。
</p>
<p>
以下にVIAの実装例とその特徴について簡単に述べる。

<dl>
<dt>Berkely VIA[3]
<dd>
ネットワークインタフェースとしてMyrinetを用いたVIA。VIの処理はMyrinet
上で行っている。レイテンシはAM2より小さいが、バンド幅はAM2と同等である。

<dt>M-VIA
<dd>
NERSCのPCクラスタプロジェクトの一部として開発されている。GigaEtherと
100Base向けのVIA。TCPに比べて1/3のレイテンシだが、100Baseの場合はバンド
幅はTCPと変わらない。GigaEtherの場合は2倍ほどのバンド幅である。

<dt>JaguarVIA[27]
<dd>
Java向けの高速なVIAインタフェース。VIAにはBerkery VIAを利用している。
JNIではなくJITコンパイラを用いて、VIAのメソッド呼び出しをnativeへの直接
呼び出しとして実現しているため、ラウンドトリップタイム・バンド幅ともに
C(native)における実装と同等の性能を達成している。

</dl>
</p>

<h5>SCore & PM & MPC++</h5>

<p>
SCore[8]はRWCPで開発されている、ユーザーレベルで実現され
たクラスタ型並列計算機向け並列実行環境である。SCoreシステムは通信ライブ
ラリPM、並列ジョブスケジューラ・並列実行環境SCore-D、並列プログラミング
言語MPC++などから構成され、スケジューリングの機構など並列実行に必要な機
能を提供する。複数ユーザーによる共有利用を目的としており、ユーザーの対話
性も視野に入れた設計が成されている。
</p>
<p>
PM[9],[26]は当初、Myrinetを対象として開
発された通信ライブラリ・ドライバで、複数のチャネルを持ち、レイテンシが低
く、高スループット、可変長メッセージのサポート、メッセージ配送の保証、メッ
セージ順序の保存、コンテキストスイッチの搭載、マルチキャストのサポート静
的ルーティングなどの機能・特徴がある。
</p>
<p>
また、PMはマルチユーザープロセスからの利用が可能となっている。
このため、PMではチャネルを用いて、物理的に一つしかないネットワークをソフ
トウェア的に多重化している。
チャネルは複数個提供されており、プロセスはチャネルを介し
て通信する。ある送信ノードのチャネルから発信されたメッセージは、受信ノー
ドの同じチャネルに配送される。
現在、PMはMyrinet以外にUDPやGiga-Ethernet上にも実現されている。
</p>
<p>
MPC++ 2.0 Level 0[12]はC++のテンプレートと継承の機能を
使って高レベルな通信モデルのプログラミングをサポートしている、並列プログ
ラミング言語である。本システムではMPC++ 2.0 Level 0のMTTLの機能であるロー
カル/リモートでのスレッド生成、グローバルポインタ、リダクションなどを用
いる。また、リフレクション機能をサポートしたLevel
1[10]もある。
</p>

<h5>HPVM & FM</h5>

<p>
HPVM(High Performance Virtual Machine)[6] は通信レイヤの
FM(Fast Message)[21]、メッセージングの
MPI-FM[17]、スケジューリングのFM-DCS[23]、
SHMEMのPut/Get-FM[7]、GlobalArrays-FMなどで構成されたク
ラスタ向けソフトウェア群である。
</p>
<p>
クラスタの形態にはresource stealingなモデルといわゆるクラスタのモデルの2
つがある。CondorやUtopia、LSFのようなresource stealingモデルは異機種で、
低性能なネットワークで結ばれており、逐次のジョブにおいてhigh throughput
を達成している。いわゆるクラスタは同機種で高速なネットワークで接続されて
いて高性能を達成している。
</p>
<p>
HPVMではこの2つを一体化する。
<ul>
<li> 高性能な通信に標準的でハイレベルなAPIを提供
<li> スケジューリングとリソース管理の一体化
<li> 異機種環境
</ul>

また、通信のパフォーマンスは並列計算では重要となるので、HPVMでは
low-level、high-levelの２つの通信レイヤから構成されている。low-levelなも
のとしてFM(Fast Message)、high-levelなものとしてMPI、SHMEM、Global
Arraysを提供している。
</p>
<dl>
<dt>通信
<dd>
<p>
ハイパフォーマンスを提供するハードウェアがあっても、伝統的なソフトウェア・
ハードウェアの構造だと、ハードウェアの性能をアプリケーションのレベルまで
持ってくるのが困難である。例えば、TCP/IPは10Mbpsのイーサーネット向けに作
られたので、100μ秒のオーバーヘッドがパケットごとにかかる。しかし、
Myrinetだと2桁以上速い.そこでHPVMではハードウェアの性能を生かす、低レベ
ルな通信としてFast Messages(FM)を用意し、さらにその上にハイレベルなAPIを
提供している。
</p>

<dt>Fast Message
<dd>
<p>
FMはもとはBerkeleyのActive Messagesである。FM1.1のAPIにはlong、shortメッ
セージの送信と、ネットワークからのメッセージの取りだしの3つの関数がある。
他のメッセージングレイヤとの違いはFM上に構築されるソフトウェアに対してサー
ビスの保証とメモリ階層の制御が提供されることである。ハイレベルのレイヤで
パフォーマンスの低下を招かないためには、低レベルのメッセージングレイヤが
次のものを提供する必要がある。

<ul>
<li> 通信の信頼性
<li> メッセージの処理の順序
<li> 通信スケジューリングの制御
</ul>

また、FM上にハイレベルのメッセージングレイヤを実装した場合、次のような問
題がある。
<ul>
<li> {\em どれだけ}の通信データが処理されるかではなく、{\em いつ}通信
           データが処理されるかの制御を許可している。
<li> FMへデータを送る前にヘッダーを付けるためにユーザーのバッファから
           コピーするコスト。
<li> FM内部のバッファから上位のメッセージングレイヤのバッファさらにユー
           ザーのバッファへコピーするコスト。
</ul>
そこでFM2.0ではdata pacingとstreamed messageを実現した。data pacingによ
りで処理されるデータの量を制限することができるようになり、streamed
messageでは送信側がメッセージをすべて送り終わる前に受信側でメッセージを
処理できるようになりさらにデータのコピーを減らすことができる。また、
streamed messagesでは上位のメッセージングレイヤがメッセージの一部を受け
取って、その後のデータを受け取るかどうかを決めることもできる。FM2.0の性
能はFM1.1とほぼ同等である。
</p>
<p>
また、FM2.0をPentiumProのWindowsNTクラスタへも実装した。PCにはwrite
combining
をサポートしたPCIバスがあるため、従来用いてきたDMAによ
るオーバーヘッドも避けられる。
</p>
<p>
Fast MessageはGAMインタフェースを用いているが、ハンドルの暗黙実行は行
わない。その代わりに、ユーザープロセスは届くメッセージ用のバッファを提供
し、デッドロックを回避するためにフローコントロールを行っている。またバル
ク転送機構なども備えている。
</p>

<dt>API
<dd>
<p>
次にハイレベルのレイヤでは高機能で使いやすいAPIを提供する必要がある。し
かし、ハイレベルのレイヤではさらにオーバーヘッドが増し、一般的に性能が低
下する。FMではハイレベルのメッセージングレイヤと低レベルのレイヤとのギャッ
プをなくすことにより、高性能なMPI-FMとGlobal Arraysの2つのAPIをFM上に実
現した。
</p>

<dt>MPI-FM
<dd>

<p>
MPI-FMはMPICHをベースにしている。MPICHではさらに2つのレイヤに分かれてお
り、1つはADIという25個ほどの関数からなり、もう1つはADIにより構築された
125個の関数である。つまり、FM上でMPI(MPICH)を動かすためにはADIのみを実装
すればよい。MPI-FMはMPP(IBM SP2)に比べて低レイテンシでさらに2kbyte以下の
メッセージで高いバンド幅を達成している。
</p>

<dt>Global Arrays
<dd>

<p>
Global Arraysは共有アドレス空間の巨大な配列のセクションへアクセス・制御
するためのPut/Getのセマンティクスを用いたプログラミングモデルである。
Global ArraysはSHMEMを用いて実装されているため、SHMEMも移植する必要があ
る。
</p>

</dl>
</p>

<h5>AM</h5>

<p>
Active Messageはもともと並列スパコン向けに作られたものだが、多くのネット
ワークインタフェースに実装された。AMは通信のための一種のアセンブリ言語
のつもりであった。内部のキュー構造を見せるのではなく、非常に単純なRPCの
ようなプログラミングインタフェースを提供していた。小さなメッセージは手
続き呼び出しによってレジスタ経由の引数として、大きなメッセージはメモリ間
の転送として扱われている。ハンドラは引数としてのメッセージデータがリモー
トで利用可能になると暗黙のうちに投げられ、リモートのユーザー空間で実行さ
れる。ハンドラは割り込みやネットワークのポーリングによっても実行される。
</p>
<p>
さらにGeneral Active Message(GAM)ではプロセスにユーザーレベルのネットワー
クを暗黙のうちに関連させ、AM2以降は仮想ネットワークのエンドポイントを明
示的にし、ユーザープロセスが複数のエンドポイントを持つことを可能にし、ス
レッドによる実行モデルを提供した。AM2のエンドポイントは単純な送信・受信
のキューを持つが、内部のデータ構造は隠されている。
</p>

<h5>U-NET</h5>
<p>
U-NET[20]はユーザーレベルのデバイスドライバから見えるディ
スクリプタキューとバッファ構造を仮想化しようとしている。U-NETはVIAにかな
り近いが、キュー構造やバッファーエリアのためのアドレス解決の方法が異なる。
U-NETは最初のEthernetやATM LAN上の高速なユーザーレベルの通信レイヤである。
</p>

<a name="2">
<h2>2.2 自己反映計算</h2>

<h3>2.2.1 理論</h3>
<p>
自己反映計算(Reflection)とは、計算システムが自分自身の構成や計算過程に関する
計算を行うことである。自己反映計算の機能を持つシステムでは、システムが自己の
構成・計算過程の表現を参照するだけでなく変更することもできる。そしてそのような
表現に対する変更は、自己の構成・計算過程そのものに反映される。
</p>
<p>
プログラミング言語やオペレーティングシステムといった記述系を自己反映計算
の機能を持つシステムとして構成することが、柔軟なソフトウェアの構築に有用
であることが認識されているのは、次のような理由からである。

<dl>
<dt>拡張性
<dd>
<p>
言語やオペレーティングシステムをアーキテクチャと実現方式の両方
	    の面でカスタマイズできるようにする。アーキテクチャのカスタマイズ
	    により、アプリケーションの持つ論理構造と言語やオペレーティングシ
	    ステムの提供する抽象化機構とのギャップを少なくすることができる。
	    一方、既存のデータ表現形式によって対象の持つ論理構造を素直に表現
	    できるにもかかわらず、実行効率が著しく悪くなる場合がある。特定の
	    データ表現の実現方式を自己反映計算でカスタマイズすることによって
	    このような効率の低下を避けることができる。
</p>

<dt>動的適応性
<dd>
<p>
 計算資源の最適配置や制御方式を、静的解析によって求めること
	    が困難な問題（分散離散事象シュミレーションにおいて、シュミレート
	    対象の挙動が予測困難な場合など）、もしくはモバイルコンピューティ
	    ング環境のように構造が動的に変化するような計算環境に対しては、自
	    己の構造や計算過程を適切に操作し、計算環境に動的に適応できるよう
	    なソフトウェアの構成方式が求められる。自己反映計算の機構を持った
	    言語やオペレーティングシステムはこのようなソフトウェアを自然な形
	    で記述できる。
</p>
</dl>

以上の2点に共通するのは本来目的とする計算のレベル(ベースレベル)と、その計算・
記述方式を制御あるいはカスタマイズするレベル(メタレベル)、そしてその間のイン
タラクションが同一の記述系に基づいていることである。自己反映計算の機構を持っ
た言語やオペレーティングシステムのアーキテクチャが適切に設計されていれば、こ
れらのレベルを独立したモジュールとして分割し、再利用することが可能になる。こ
のようなモジュール化の方式は従来のプログラミング言語の設計やプログラミング方
法論ではほとんど意識されることはなかった。しかしこれによって、従来個別の方法
で導入されてきた機能（資源管理、例外処理、デバッグ機能、外界とのインターフェー
スなど）を、言語を提供するアーキテクチャにもとづいた整合的な方式で導入できる。
つまり自己反映計算とは新しいモジュール化手法を与えるソフトウェアの構成原理と
みなすことができる。
</p>

<h4>メタオブジェクト・メタクラス</h4>
<p>
オブジェクト指向言語において、クラス・メッセージ・メソッドなどをオブジェクト
として統一的に実現している言語・計算モデルの諸概念を実現しているオブジェクト
をメタオブジェクトという。メタオブジェクトは言語のメタインタプリタの実現であ
る。メタオブジェクトの導入によって、オブジェクト指向言語は手続き的リフレクショ
ンを実現することができる。
</p>

<h4>メタオブジェクトプロトコル</h4>
<p>
メタオブジェクトのインタフェースの仕様をメタオブジェクトプロトコルとい
う。メタオブジェクトプロトコルでは、メタオブジェクトのクラス定義そのもの
は与えずに、それらのクラスに関係する総称関数および付随するメソッドの自然
言語による外部仕様を与えている。これにより具体的な実装からは独立にメタオ
ブジェクトの仕様や利用方法を与えている。また、メタオブジェクトのカスタマ
イズは、継承を用いることによって局所的に行うことができる。この結果、カス
タマイズしたシステムの安全性や再利用性を確保することができる。
メタオブジェクトプロトコル(MOP)には次の２タイプある。
</p>
<dl>
<dt>ランタイムMOP
<dd>
<p>
	    初期の手続き的自己反映計算のほとんどが、このタイプのメタオブ
	    ジェクトプロトコルを実装していた。オーバーヘッドが大きい。
	    例えば、
	    CLOSのメタオブジェクトプロトコルではメタオブジェクトの実行時
	    のメソッドインヴォケーションによってオブジェクトシステムを実
	    行しているので、実行時のパフォーマンスを挙げることは難しい。
</p>
<dt>コンパイルタイムMOP
<dd>
<p>
	    コンパイルタイムMOPは言語の振舞の変更などのメタ計算を、ソー
	    スコードの変換として記述させ、コンパイル時にそのメタ計算を実
	    行することで実行時のオーバーヘッドを減らすことができる。
	    しかし、ランタイムMOPとは違い、コンパイラが扱うデータを独立
	    して制御することが難しい、MOPによって変更され異なる方針でコ
	    ンパイルされたデータを正しく組み合わせるのが難しいなどの問題
	    もある。[16]
</p>
</dl>

<h3>2.2.2 関連研究</h3>
<h5>OpenC++</h5>
<p>
OpenC++[4],[5]はC++言語のための
Compile-time MOPを提供する。適切なメタクラスを記述し、それをOpenC++コン
パイラによってプログラム変換を含む適切な処理を行うコンパイラを生成する。
生成されたコンパイラを用いてベースレベルのプログラムの変換、コンパイルを
行う。Compile-time MOPによりメタ計算の実行時オーバーヘッドがなくすことが
できる。
</p>
<p>
OpenC++のメタオブジェクトプロトコルの基本的なアーキテクチャは、クラスの
メタオブジェクト、関数のメタオブジェクトがあり、これらのメタオブジェクト
がプログラムの振舞を操作している。OpenC++の場合、普通のオブジェクトはラ
ンタイムにのみ存在し、メタオブジェクトはコンパイルタイムにのみ存在する。
このため、メタオブジェクトがオブジェクトの振舞はプログラムをコンパイルす
る時に操作するということなる。このとき、メタオブジェクトは適当にプログラ
ムのトップレベルの定義を変換し、必要があれば変換したコードのための実行時
の関数や型、データなどを追加する。これによってメタオブジェクトは実行時の
スペースとスピードでペナルティーがまったくない。
OpenC++の処理プロセスは以下のようになっている

<ul>
 <li> 
<p>
プログラムの解析が終わると、メタオブジェクトプロトコルは２つのメタオブジェ
クト、クラスPointのためのメタオブジェクトとメンバー関数MoveTo()のための
メタオブジェクトをつくる。普通、クラスのメタオブジェクトはクラスClassのイ
ンスタンスとなる。これにはクラスの定義によって与えられる名前やベースのク
ラス、メンバーなどの情報が含まれている。関数のメタオブジェクトは普通クラ
スFunctionのインスタンスとなる。これにも同じように関数の定義からくる名前
やパラメータ、関数本体の解析木の情報が含まれている。これはメンバー関数な
ので、このメンバー関数を持っているクラスのメタオブジェクトへのポインタも
持っている。
</p>
 <li> 
<p>
メタオブジェクトの定義のあるもとのバラバラになったコードの代わりに適当な
コードをつくるためにメタオブジェクトを呼ぶために、各メタオブジェクトのメ
ンバー関数のCompileSelf()が呼び出される。その後、クラスのメタオブジェク
トはそれらのクラスのための普通のC++定義を解析木の形で生成する。これは普
通、もとの定義だけを生成する。同じように、関数のメタオブジェクトはこれも
また解析木の形で普通のC++の定義を生成する。これも普通、もとの定義だけを
生成する。関数の本体を変換するために、関数のメタオブジェクトは関数の解析
木を一つ一つ辿って適当なクラスのメタオブジェクトに各関数本体のコード片の
を変換するかどうか照会するサブプロトコルを呼ぶ。
関数のメタオブジェクトはクラスのメタオブジェクトのクエリーをつくることに
よって関数本体をコンパイルするので、プログラムのコンパイルは主に、クラス
メタオブジェクトが行う。クラスのメタオブジェクトの通常の動作は一切変換を
せずに、与えられた解析木を返すだけである。
</p>

 <li> 
<p>
あるメタオブジェクトからつくられた解析木はまとめられて、C++のソースファ
イルに変換される。このソースファイルはC++コンパイラによってコンパイルさ
れる。メタオブジェクトプロトコルがC++コンパイラの分離したプリプロセッサ
として実装されているので、変換されたC++のソースファイルはテキストファイ
ルなのでC++コンパイラはこのファイルの内容を再び解析しなくてはならない。
OpenC++ではこのオーバーヘッドを避けるために、C++コンパイラとメタオブジェ
クトプロトコルを統合してある。
</p>

</ul>

このようにOpenC++のメタオブジェクトプロトコルはOpenC++からC++へのソース
toソースの変換をコントロールするものである。
</p>

<h5>OpenJIT</h5>
<p>
OpenJIT[18],[31]は、自己反映計算(リフ
レクション)に基づいたOpen Compiler(開放型コンパイラ)技
術をベースとして、アプリケーションや計算環境に特化した言語の機能拡張と最
適化が行えるJITコンパイラである。OpenJITでは、
JITコンパイラ自身がJavaのクラスフレームワークとして記述されており、クラ
スライブラリの作成者がクラス単位でそのクラスに固有の最適化モジュールを組
み込むことを可能としている。これにより、様々な計算環境・プラットフォーム・ア
プリケーションに対する適合や、複雑な最適化を組み込むことも可能となってい
る。
</p>
<p>
OpenJITの機能は、大きく分けてフロントエンド系
[19],[30]の処理とバックエンド系の処理の2つ
から構成される。フロントエンド系は、Javaのバイトコードを入力とし、高レベ
ルな最適化を施して、バックエンドに渡す内部的中間表現、あるいは再びバイト
コードを出力する。バックエンド系は、得られた中間表現あるいはバイトコード
に対し、より細かいレベルでの最適化を行い、ネイティブコードを出力する。
<p>
</p>
以下では、フロントエンド系とバックエンド系のそれぞれの処理について述べる。

<dl>
<dt>フロントエンド
<dd>
<p>
 OpenJITの起動は、JDKの提供するJITインタフェースを介してメソッド起動
ごとに行われる。OpenJITが与えられたメソッドに対して起動されると、フロ
ントエンド系は対象となるバイトコード列に対して以下の処理を行う。
</p>
<p>
まず、ディスコンパイラモジュールがバイトコードからASTを逆変換により得
る。この際には、与えられたバイトコード列から、元のソースプログラムから
生成されるコントロールグラフの復元を行う。同時に、アノテーション解析モ
ジュールによって、対象となるクラスファイルに何らかのアノテーション情報
が付記されていた場合にその情報を得る。この情報は、AST上の付加情報とし
て用いられる。
</p>
<p>
次に得られたASTに対し、最適化モジュールによって最適化が施される。最適
化は、通常のASTとフローグラフを用いた構築・解析・変換を行い、最適化モ
ジュールのサポートモジュールであるフローグラフ構築モジュール、フローグ
ラフ解析モジュール、プログラム変換モジュールを用いて実現される。フロー
グラフ構築モジュールは対応するデータ依存グラフ、コントロール依存グラフ
等を生成する。フローグラフ解析モジュールはこれらのデータフローグラフに
対するデータフロー問題、マージ、浮動点検出等の諸ルーチンをメソッドとし
て提供する。プログラム変換モジュールは解析情報を元にテンプレートマッチ
ングによってAST上の変換を行う。
</p>
<p>
変換後の結果はバックエンドが必要とする中間表現ないしバイトコードに変換
されて、出力される。
</p>

<dt>バックエンド
<dd>
<p>
バックエンド系はフロントエンド系によって出力された中間表現ないしバイト
コードに対して、低レベルの最適化処理を行い、ネイティブコードを出力する。
ネイティブコード変換モジュールはバックエンド系処理全体の抽象フレームワー
クであり、バックエンド系のモジュールのインタフェースを定義する。このイ
ンタフェースに沿って具体的なプロセッサに応じたクラスでモジュールを記述
することにより、様々なプロセッサに対応することが可能となる。
</p>
<p>
まず、中間コード変換モジュールによって、バイトコードの命令を解析して分
類することにより、スタックオペランドを使った中間言語の命令列へと変換を
行う。フロントエンド系が中間表現を出力する場合はこの形式で出力するため、
この変換処理は省略される。次にRTL変換モジュールは、得られた命令列に対
し、スタックオペランドを使った中間言語から仮想的なレジスタを使った中間
言語(RTL)へ変換する。この際、バイトコードの制御の流れを解析し、命令列
を基本ブロックに分割する。また、バイトコードの各命令の実行時のスタック
の深さを計算することで、スタックオペランドから無限個数あると仮定した仮
想的なレジスタオペランドに変換する。
</p>
<p>
次に、Peephole最適化モジュールによって、RTLの命令列の中から冗長な命令
を取り除く最適化を行い、最適化されたRTLが出力される。最後にOpenJIT
SPARC プロセッサコード出力モジュールにより、SPARCプロセッサのネイティ
ブコードが出力される。出力されたネイティブコードは、JavaVMによって呼び
出され実行されるが、その際にOpenJIT ランタイムモジュールを補助的に呼び
出す。
</p>
</dl>

<h5>EPP</h5>
<p>
EPP[11]は、Javaの柔軟な言語拡張(文法や意味)を提供する
プリプロセッサである。EPP自身、EPP で拡張された Java 言語で記述されてい
る。EPPにおける言語拡張では、EPP pluginを利用する。plug-in 同士の衝突が
起きなければ、複数のplug-in を同時に取り込むこともできる。EPPプリプロセッ
サが出力するコードはJava ソースコードであるため、通常のJavaコンパイラで
コンパイルすることができる。EPPは汎用手続き型言語的な記述が可能なため、
文脈依存、大域脱出など、BNF 記法では書きにくいad-hoc な処理が行ないやす
い。
</p>
<p>
EPPの言語拡張機能は、pluginでもあるSymbolとSystemMixinの機構によって実現
されている。Symbolはコロンとそれに続くidentifierまたは文字列リテラルで表
される。このSymbolとはC言語のenum文で宣言された定数に近いが、あらかじめ
有限個の要素を宣言しておく必要がなく、ソースコード中必要に応じて任意の名
前(文字列)を持つsymbolを使うことができる。文字列リテラルにも近いが、文字
列とは違い、実行時にはポインタの比較だけで高速に同一性の判定ができ、名前
を指定してsymbolを動的に生成することもできる。なお、同一の名前を持つ
symbol リテラルは、同じidentity を持つインスタンスを参照することが保証さ
れる。
<p>
</p>
SystemMixinは、複数のクラスの部品となるmixinをいくつかまとめたもので、
collaboration-deginを実現している。mixinは定義時に特定のスーパークラスを
指定しないで定されたクラスである。mixinは後で他のクラスによて多重継承さ
れ、直列化されることよりスーパークラスが決まることを想定して定義される。
EPPは標準のJava言語パーザを実現するmixinとソースコードで指定されたPlugIn
を組み合わせて1つのプリプロセッサとして動作する。
</p>

<h5>CLOS</h5>
<p>
CLOS[13]はLispにオブジェクト指向言語機能を取り入れたも
のである。このCLOSと、同様にLispにオブジェクト指向言語機能を取り入れた
FlavorsやLOOPSの大きな違いは メタオブジェクトプロトコルを持つことである。
CLOSではCLOSを実現するクラス、メソッドなどの諸要素はメタオブジェクトとし
て表現されている。そしてこれらのメタオブジェクトはCLOSそのものであり、つ
まりCLOSのメタインタプリタを構成している。
</p>
<p>
また、CLOSのメタオブジェクトは普通のオブジェクトと同じアドレス空間に存在
している。よって、各メタレベルで共通のメタオブジェクトはすべて同一のもの
である。つまり、無限階のリフレクティブタワーの代わりに循環的な構造を持つ。
この循環的構造はリフレクティブタワーによるものとほぼ等価な系を構成する。
すべてのオブジェクト・メタオブジェクトが同一のアドレス空間に存在している
ことから、ユーザープログラム内からメタオブジェクトへのアクセスには特別な
言語機構は必要なく、通常の総称関数呼び出しを用いることができる。またカス
タマイズしたいメタオブジェクトに関するクラス定義も、通常の定義と同様に行
うことができる。
</p>
<p>
CLOSのメタオブジェクトプロトコルではメタオブジェクトのクラス定義は与えら
れていない。そのかわりに、それらのクラスに関係する総称関数および付随する
メソッドの自然言語による外部仕様を与えている。つまり、CLOSのメタオブジェ
クトプロトコルでは具体的な実装からは独立にメタオブジェクトの仕様や利用方
法を与えている。
</p>

<h5>OpenJava</h5>
<p>
OpenJava[24]ではJDKのReflectionAPIを拡張する形で、既存の
introspectionに加えてintercessionを提供する。
introspectionは実行時にクラスのメンバなどを調べたり利用する機能でクラス
の実装情報を知ることができる。intercessionは実行時にメソッド呼び出しの動
作を変更したりクラスに新たなメソッドを追加したりする機能である。この
intercessionの機能により、言語自体の拡張を備えたライブラリを作成すること
ができる。
</p>
<p>
しかし、このintercessionの実行効率のよい実装は困難である。これを改善す
るためにOpenC++でも用いられたコンパイルタイムMOPを用いている。OpenC++の
コンパイルタイムMOPは静的な型に基づいているが、JDKのReflectionAPIではオ
ブジェクトの動的な型に基づいているため、OpenJavaでも動的な型に基づくコン
パイルタイムMOPを採用している。これにより単一のMOPがintrospectionと
intercessionを提供できるようになり、プログラマは両者の区別を意識せずに自
己反映計算を伴うプログラムを書くことができる。
</p>

<h5>BCA</h5>
<p>
Binary Component Adaptation(BCA)[14],[15]
はコンポーネントのバイナリレベルでのオンザフライな適応を提供している。
BCAはソースコードへのアクセスなしで、プログラムのリリース間のコンパチビ
リティを保証しながら、コンポーネントのロード時かロード中にコンポーネント
のバイナリを変更する。つまりadaptationは、対象が以前のリリースと互換性が
ある限り、コンポーネントの新しいバイナリと以前のバイナリの互換性を保証し
ている。このadaptationでは、各クラスに対するdeltaファイルを用いて実現さ
れる。deltaファイルでは拡張・変換したいクラスに対して用意し、deltaファイ
ルコンパイラでコンパイルする。そして、クラスのロード時にmodifierによって
既存のクラスファイルに対してdeltaファイルを適用し、クラスファイルの内容
を変更する。
</p>

<hr>
[ <a href="1.html">前章</a>
| <a href="index.html">目次</a>
| <a href="3.html">次章</a> ]
</body>
</html>
